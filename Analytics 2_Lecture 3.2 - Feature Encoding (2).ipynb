{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ba6886",
   "metadata": {},
   "source": [
    "### The Goal of the Script is to perform:\n",
    "Feature Engineering: Feature Encoding (Converting the Categorical Features into Numerical Features)\n",
    "\n",
    "### Four approaches were covered in the lecture:\n",
    "1. Ordinal Encoding\n",
    "2. One-hot Encoding\n",
    "3. Label Encoding\n",
    "4. Feature Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fff959",
   "metadata": {},
   "source": [
    "### Environment Setup for performing Feature Encoding on Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0b36c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries to train the model\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Library for Evaluating the model\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7048dd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>...</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>85 Turner St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>3/12/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/02/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>5 Charles St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>40 Federation La</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.7969</td>\n",
       "      <td>144.9969</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>55a Park St</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>VB</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>4/06/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8072</td>\n",
       "      <td>144.9941</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Suburb           Address  Rooms Type      Price Method  \\\n",
       "0           1  Abbotsford      85 Turner St      2    h  1480000.0      S   \n",
       "1           2  Abbotsford   25 Bloomburg St      2    h  1035000.0      S   \n",
       "2           4  Abbotsford      5 Charles St      3    h  1465000.0     SP   \n",
       "3           5  Abbotsford  40 Federation La      3    h   850000.0     PI   \n",
       "4           6  Abbotsford       55a Park St      4    h  1600000.0     VB   \n",
       "\n",
       "  SellerG       Date  Distance  ...  Bathroom  Car  Landsize  BuildingArea  \\\n",
       "0  Biggin  3/12/2016       2.5  ...       1.0  1.0     202.0           NaN   \n",
       "1  Biggin  4/02/2016       2.5  ...       1.0  0.0     156.0          79.0   \n",
       "2  Biggin  4/03/2017       2.5  ...       2.0  0.0     134.0         150.0   \n",
       "3  Biggin  4/03/2017       2.5  ...       2.0  1.0      94.0           NaN   \n",
       "4  Nelson  4/06/2016       2.5  ...       1.0  2.0     120.0         142.0   \n",
       "\n",
       "   YearBuilt  CouncilArea  Lattitude Longtitude             Regionname  \\\n",
       "0        NaN        Yarra   -37.7996   144.9984  Northern Metropolitan   \n",
       "1     1900.0        Yarra   -37.8079   144.9934  Northern Metropolitan   \n",
       "2     1900.0        Yarra   -37.8093   144.9944  Northern Metropolitan   \n",
       "3        NaN        Yarra   -37.7969   144.9969  Northern Metropolitan   \n",
       "4     2014.0        Yarra   -37.8072   144.9941  Northern Metropolitan   \n",
       "\n",
       "   Propertycount  \n",
       "0         4019.0  \n",
       "1         4019.0  \n",
       "2         4019.0  \n",
       "3         4019.0  \n",
       "4         4019.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset: Dataset is the Melbourne House Pricing Dataset\n",
    "# It is a Regression problem where the goal is to predict the house price based on features of the house\n",
    "data = pd.read_csv('melbourne_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5308333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the dataset to solve the Regression Problem\n",
    "\n",
    "# Prepare the Dependent feature, i.e., Price of the house as the Dependent feature\n",
    "y = data.Price\n",
    "\n",
    "# Features other than Price feature are now considered as Independent features\n",
    "\n",
    "# Assumption:\n",
    "# To solve the regression problem, for simplicity only numerical independent features are considered\n",
    "X = data.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c11666b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18396 entries, 0 to 18395\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0     18396 non-null  int64  \n",
      " 1   Suburb         18396 non-null  object \n",
      " 2   Address        18396 non-null  object \n",
      " 3   Rooms          18396 non-null  int64  \n",
      " 4   Type           18396 non-null  object \n",
      " 5   Method         18396 non-null  object \n",
      " 6   SellerG        18396 non-null  object \n",
      " 7   Date           18396 non-null  object \n",
      " 8   Distance       18395 non-null  float64\n",
      " 9   Postcode       18395 non-null  float64\n",
      " 10  Bedroom2       14927 non-null  float64\n",
      " 11  Bathroom       14925 non-null  float64\n",
      " 12  Car            14820 non-null  float64\n",
      " 13  Landsize       13603 non-null  float64\n",
      " 14  BuildingArea   7762 non-null   float64\n",
      " 15  YearBuilt      8958 non-null   float64\n",
      " 16  CouncilArea    12233 non-null  object \n",
      " 17  Lattitude      15064 non-null  float64\n",
      " 18  Longtitude     15064 non-null  float64\n",
      " 19  Regionname     18395 non-null  object \n",
      " 20  Propertycount  18395 non-null  float64\n",
      "dtypes: float64(11), int64(2), object(8)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get the information about the features present in the dataset\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205a0e60",
   "metadata": {},
   "source": [
    "We can observe that the \"Date\" column is present as an Object data type instead of Datetime datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d538efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As \"Date\" column is presented as an Object datatype, let us convert the datatype of Date column to date time format\n",
    "X['Date'] = pd.to_datetime(X['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3010fea3",
   "metadata": {},
   "source": [
    "### Handle the missing values for Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f3f22",
   "metadata": {},
   "source": [
    "1. Handle Missing Values for Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7fbd3e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features:\n",
      "['Suburb', 'Address', 'Type', 'Method', 'SellerG', 'CouncilArea', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "# Get list of categorical features\n",
    "categorical_features = (X.dtypes == 'object')\n",
    "object_cols = list(categorical_features[categorical_features].index)\n",
    "\n",
    "print(\"Categorical features:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f07a456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for the categorical features\n",
    "categorical_dataset = X[object_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cf8aea3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CouncilArea', 'Regionname']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get categorical features with missing values\n",
    "cols_with_missing = [col for col in categorical_dataset.columns\n",
    "                     if categorical_dataset[col].isnull().any()]\n",
    "\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04570ca7",
   "metadata": {},
   "source": [
    "There are two features \"CouncilArea\", and \"Regionname\" with the missing values. Therefore, apply imputation approach to fill in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5a672165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation Approach on the Indepdent features, i.e., replacing all the missing value \n",
    "# in a feature with a FIXED Value\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "univariate_imputer = SimpleImputer(strategy='most_frequent', missing_values=np.nan)\n",
    "imputed_categorical_features = pd.DataFrame(univariate_imputer.fit_transform(categorical_dataset))\n",
    "imputed_categorical_features.columns = categorical_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94fca75",
   "metadata": {},
   "source": [
    "2. Handle Missing Values for Numerical Values using Extended Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f4c81271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features:\n",
      "['Unnamed: 0', 'Rooms', 'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude', 'Propertycount']\n"
     ]
    }
   ],
   "source": [
    "# Get list of Numerical features\n",
    "numeric_features = (X.dtypes != 'object')\n",
    "numeric_cols = list(numeric_features[numeric_features].index)\n",
    "\n",
    "print(\"Numeric features:\")\n",
    "print(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e5e76096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for the numeric features\n",
    "numeric_dataset = X[numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5b74c210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Distance',\n",
       " 'Postcode',\n",
       " 'Bedroom2',\n",
       " 'Bathroom',\n",
       " 'Car',\n",
       " 'Landsize',\n",
       " 'BuildingArea',\n",
       " 'YearBuilt',\n",
       " 'Lattitude',\n",
       " 'Longtitude',\n",
       " 'Propertycount']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get numerical features with missing values\n",
    "cols_with_missing = [col for col in numeric_dataset.columns\n",
    "                     if numeric_dataset[col].isnull().any()]\n",
    "\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "75354945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-125-dacf24576dba>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  numeric_dataset[col + '_was_missing'] = numeric_dataset[col].isnull()\n"
     ]
    }
   ],
   "source": [
    "# Make new columns indicating what will be imputed\n",
    "for col in cols_with_missing:\n",
    "    numeric_dataset[col + '_was_missing'] = numeric_dataset[col].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "56f445dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_dataset = numeric_dataset.drop(['Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "85deb07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation Approach on the Indepdent features, i.e., replacing all the missing value \n",
    "# in a feature with a FIXED Value\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "univariate_imputer_mean = SimpleImputer(strategy='mean', missing_values=np.nan)\n",
    "imputed_numerical_features = pd.DataFrame(univariate_imputer_mean.fit_transform(numeric_dataset))\n",
    "imputed_numerical_features.columns = numeric_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c2356146",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imputed = pd.concat([imputed_categorical_features, imputed_numerical_features], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cb1d0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc03b8e",
   "metadata": {},
   "source": [
    "### Label Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860712b",
   "metadata": {},
   "source": [
    "Label EncoderÂ encode feature with a value between 0 and n_classes-1 where n is the number of distinct values present in the feature. If a label repeats, it assigns the same value as assigned earlier. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3d373d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Library to perform Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1409cc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features:\n",
      "['Suburb', 'Address', 'Type', 'Method', 'SellerG', 'CouncilArea', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "# Get list of categorical features\n",
    "categorical_features = (X_imputed.dtypes == 'object')\n",
    "object_cols = list(categorical_features[categorical_features].index)\n",
    "\n",
    "print(\"Categorical features:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8517bd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>...</th>\n",
       "      <th>Postcode_was_missing</th>\n",
       "      <th>Bedroom2_was_missing</th>\n",
       "      <th>Bathroom_was_missing</th>\n",
       "      <th>Car_was_missing</th>\n",
       "      <th>Landsize_was_missing</th>\n",
       "      <th>BuildingArea_was_missing</th>\n",
       "      <th>YearBuilt_was_missing</th>\n",
       "      <th>Lattitude_was_missing</th>\n",
       "      <th>Longtitude_was_missing</th>\n",
       "      <th>Propertycount_was_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17365</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8233</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13470</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>12439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14496</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18391</th>\n",
       "      <td>320</td>\n",
       "      <td>17042</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>23540.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18392</th>\n",
       "      <td>320</td>\n",
       "      <td>18046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>23541.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18393</th>\n",
       "      <td>326</td>\n",
       "      <td>4665</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>23544.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18394</th>\n",
       "      <td>328</td>\n",
       "      <td>14735</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>273</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>23545.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18395</th>\n",
       "      <td>328</td>\n",
       "      <td>10741</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>273</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>23546.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18396 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Suburb  Address  Type  Method  SellerG  CouncilArea  Regionname  \\\n",
       "0           0    17365     0       1       29           31           2   \n",
       "1           0     8233     0       1       29           31           2   \n",
       "2           0    13470     0       3       29           31           2   \n",
       "3           0    12439     0       0       29           31           2   \n",
       "4           0    14496     0       4      178           31           2   \n",
       "...       ...      ...   ...     ...      ...          ...         ...   \n",
       "18391     320    17042     1       3      100           23           6   \n",
       "18392     320    18046     0       0      254           23           6   \n",
       "18393     326     4665     0       1       38           23           2   \n",
       "18394     328    14735     0       3      273           23           6   \n",
       "18395     328    10741     0       4      273           23           6   \n",
       "\n",
       "       Unnamed: 0  Rooms  Distance  ...  Postcode_was_missing  \\\n",
       "0             1.0    2.0       2.5  ...                   0.0   \n",
       "1             2.0    2.0       2.5  ...                   0.0   \n",
       "2             4.0    3.0       2.5  ...                   0.0   \n",
       "3             5.0    3.0       2.5  ...                   0.0   \n",
       "4             6.0    4.0       2.5  ...                   0.0   \n",
       "...           ...    ...       ...  ...                   ...   \n",
       "18391     23540.0    2.0       6.8  ...                   0.0   \n",
       "18392     23541.0    4.0       6.8  ...                   0.0   \n",
       "18393     23544.0    4.0      12.7  ...                   0.0   \n",
       "18394     23545.0    4.0       6.3  ...                   0.0   \n",
       "18395     23546.0    4.0       6.3  ...                   0.0   \n",
       "\n",
       "       Bedroom2_was_missing  Bathroom_was_missing  Car_was_missing  \\\n",
       "0                       0.0                   0.0              0.0   \n",
       "1                       0.0                   0.0              0.0   \n",
       "2                       0.0                   0.0              0.0   \n",
       "3                       0.0                   0.0              0.0   \n",
       "4                       0.0                   0.0              0.0   \n",
       "...                     ...                   ...              ...   \n",
       "18391                   0.0                   0.0              0.0   \n",
       "18392                   0.0                   0.0              0.0   \n",
       "18393                   0.0                   0.0              0.0   \n",
       "18394                   0.0                   0.0              0.0   \n",
       "18395                   0.0                   0.0              0.0   \n",
       "\n",
       "       Landsize_was_missing  BuildingArea_was_missing  YearBuilt_was_missing  \\\n",
       "0                       0.0                       1.0                    1.0   \n",
       "1                       0.0                       0.0                    0.0   \n",
       "2                       0.0                       0.0                    0.0   \n",
       "3                       0.0                       1.0                    1.0   \n",
       "4                       0.0                       0.0                    0.0   \n",
       "...                     ...                       ...                    ...   \n",
       "18391                   1.0                       0.0                    0.0   \n",
       "18392                   0.0                       0.0                    0.0   \n",
       "18393                   1.0                       1.0                    1.0   \n",
       "18394                   0.0                       0.0                    0.0   \n",
       "18395                   1.0                       0.0                    0.0   \n",
       "\n",
       "       Lattitude_was_missing  Longtitude_was_missing  \\\n",
       "0                        0.0                     0.0   \n",
       "1                        0.0                     0.0   \n",
       "2                        0.0                     0.0   \n",
       "3                        0.0                     0.0   \n",
       "4                        0.0                     0.0   \n",
       "...                      ...                     ...   \n",
       "18391                    0.0                     0.0   \n",
       "18392                    0.0                     0.0   \n",
       "18393                    0.0                     0.0   \n",
       "18394                    0.0                     0.0   \n",
       "18395                    0.0                     0.0   \n",
       "\n",
       "       Propertycount_was_missing  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "...                          ...  \n",
       "18391                        0.0  \n",
       "18392                        0.0  \n",
       "18393                        0.0  \n",
       "18394                        0.0  \n",
       "18395                        0.0  \n",
       "\n",
       "[18396 rows x 31 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the Dataset, seven categorical features are present\n",
    "# Therefore, we will perform Label Encoding on these feature\n",
    "le = LabelEncoder()\n",
    "for i in object_cols:\n",
    "    X_imputed[i] = le.fit_transform(X_imputed[i])\n",
    "\n",
    "X_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c535b",
   "metadata": {},
   "source": [
    "We can observe that Categorical column is label encoded where categorical columns are encoded by alloting an index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab43d4",
   "metadata": {},
   "source": [
    "Depending on the data, label encoding introduces a new problem. For example, we have encoded a set of country names into numerical data. This is actually categorical data and there is no relation, of any kind, between the rows.\n",
    "The problem here is since there are different numbers in the same column, the model will misunderstand the data to be in some kind of order, 0 < 1 < 2.\n",
    "The model may derive a correlation like as the country number increases the population increases but this clearly may not be the scenario in some other data or the prediction set. To overcome this problem, we use One Hot Encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8da32727",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_label, X_valid_label, y_train_label, y_valid_label = train_test_split(X_imputed, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ded3d26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE after Label Encoding:\n",
      "179618.08135054348\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE after Label Encoding:\")\n",
    "print(score_dataset(X_train_label, X_valid_label, y_train_label, y_valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e7ac84",
   "metadata": {},
   "source": [
    "### Ordinal Encoding\n",
    "\n",
    "\n",
    "An ordinal encoding involves mapping each unique label to an integer value. This type of encoding is really only appropriate if there is a known relationship between the categories. This relationship does exist for some of the variables in our dataset, and ideally, this should be harnessed when preparing the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "174660ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE after Ordinal Encoding:\n",
      "179618.08135054348\n"
     ]
    }
   ],
   "source": [
    "X_imputed_ordinal = pd.concat([imputed_categorical_features, imputed_numerical_features], axis=1, ignore_index=False)\n",
    "\n",
    "# Import Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Library to perform Ordinal Encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Get list of categorical features\n",
    "categorical_features = (X_imputed_ordinal.dtypes == 'object')\n",
    "object_cols = list(categorical_features[categorical_features].index)\n",
    "\n",
    "# In the Dataset, seven categorical features are present\n",
    "# Therefore, we will perform Ordinal Encoding on these feature\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X_imputed_ordinal[object_cols] = ordinal_encoder.fit_transform(X_imputed_ordinal[object_cols])\n",
    "\n",
    "X_train_ordinal, X_valid_ordinal, y_train_ordinal, y_valid_ordinal = train_test_split(X_imputed_ordinal, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "print(\"MAE after Ordinal Encoding:\")\n",
    "print(score_dataset(X_train_ordinal, X_valid_ordinal, y_train_ordinal, y_valid_ordinal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9020077",
   "metadata": {},
   "source": [
    "### One Hot Encoding \n",
    "We use the OneHotEncoder class from scikit-learn to get one-hot encodings. \n",
    "There are a number of parameters that can be used to customize its behavior.\n",
    "\n",
    "We set handle_unknown='ignore' to avoid errors when the validation data contains classes that aren't represented in the training data, and\n",
    "setting sparse=False ensures that the encoded columns are returned as a numpy array (instead of a sparse matrix).\n",
    "\n",
    "To use the encoder, we supply only the categorical columns that we want to be one-hot encoded. \n",
    "\n",
    "For instance, to encode the training data, we supply X_train[object_cols]. (object_cols in the code cell below is a list of the column names with categorical data, and so X_train[object_cols] contains all of the categorical data in the training set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2913b645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE after One-Hot Encoding:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171575.36725815217\n"
     ]
    }
   ],
   "source": [
    "X_imputed_one_hot = pd.concat([imputed_categorical_features, imputed_numerical_features], axis=1, ignore_index=False)\n",
    "\n",
    "# Import Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Library to perform Ordinal Encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Get list of categorical features\n",
    "categorical_features = (X_imputed_one_hot.dtypes == 'object')\n",
    "object_cols = list(categorical_features[categorical_features].index)\n",
    "\n",
    "# In the Dataset, seven categorical features are present\n",
    "# Therefore, we will perform One-Hot Encoding on these feature\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols = pd.DataFrame(OH_encoder.fit_transform(X_imputed_one_hot[object_cols]))\n",
    "OH_cols.index = X_imputed_one_hot.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X = X_imputed_one_hot.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X = pd.concat([num_X, OH_cols], axis=1)\n",
    "\n",
    "X_train_OH, X_valid_OH, y_train_OH, y_valid_OH = train_test_split(OH_X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "print(\"MAE after One-Hot Encoding:\")\n",
    "print(score_dataset(X_train_OH, X_valid_OH, y_train_OH, y_valid_OH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d583d91f",
   "metadata": {},
   "source": [
    "### Feature Hashing\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html#:~:text=Implements%20feature%20hashing%2C%20aka%20the,column%20corresponding%20to%20a%20name.\n",
    "\n",
    "Can be used to perform feature hashing of categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86eedf0",
   "metadata": {},
   "source": [
    "### In class assignment -\n",
    "\n",
    "House Price Prediction - https://www.kaggle.com/c/home-data-for-ml-course/data\n",
    "\n",
    "Take this data into consideration figure out which features contain missing data, and apply label and one hot encoding on the categorical data.\n",
    "\n",
    "Take the train.csv into consideration.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

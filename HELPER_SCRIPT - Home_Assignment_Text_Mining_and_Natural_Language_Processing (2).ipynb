{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO6ghqhlyD7P"
      },
      "outputs": [],
      "source": [
        "# Install the library for fetching the dataset from the Huggingface Library\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using get_dataset_config_names, we can extract the information about the datasets\n",
        "# Please not using this function the dataset wont be downloaded on your system\n",
        "\n",
        "from datasets import get_dataset_config_names"
      ],
      "metadata": {
        "id": "J7Zdly_6zKtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset name that needs to be consider for the Home Assignment\n",
        "# https://huggingface.co/datasets/pile-of-law/pile-of-law\n",
        "\n",
        "dataset_name = \"pile-of-law/pile-of-law\"\n",
        "data = get_dataset_config_names(dataset_name)\n",
        "len(data) # There are 34 different corpus in this dataset representing different documents in legal domain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtS-3A_yzPpn",
        "outputId": "df9d869c-aaf1-431c-aca8-8338570e4211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of all the corpus present in the dataset\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "uozSR2SNf71p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on the alloted corpus to the student\n",
        "# Specific corpus must be downloaded for further analysis\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "euro_parl_dataset = load_dataset(path=dataset_name, name='alloted_student_dataset_name')\n",
        "euro_parl_dataset"
      ],
      "metadata": {
        "id": "5cDncT1HzYhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the corpus comprises of train, dev, test split then only train set must be considered\n",
        "# for the home-assignment\n",
        "\n",
        "train_ds = euro_parl_dataset[\"train\"]\n",
        "train_ds"
      ],
      "metadata": {
        "id": "qmEv40gbzidP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Consider only the column comprising of the \"Text\" information from the corpus\n",
        "\n",
        "train_ds[i]['text']"
      ],
      "metadata": {
        "id": "Q959u-Z0z3oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Analysis Code Goes Here**"
      ],
      "metadata": {
        "id": "Dljdsv7KM3jV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oncno4CDM8GB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analytics II - NLP Practise Text Mining_Answers.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGGoF3dkGvSi"
      },
      "source": [
        "# Analytics II\n",
        "## Natural Language Processing\n",
        "\n",
        "\n",
        "\n",
        "1.   Introduction\n",
        "2.   Working with String\n",
        "3.   Feature Extraction / Representation\n",
        "4.   Feature Expansion\n",
        "5.   Sentiment Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "UVnbx9DdGl6V",
        "outputId": "c733646c-cec2-4a74-aac0-7318164df922"
      },
      "source": [
        "# Amazon_reviews\n",
        "# DataSet: https://nijianmo.github.io/amazon/index.html\n",
        "import pandas as pd\n",
        "\n",
        "amazon_reviews_df = pd.read_json('http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Magazine_Subscriptions.json.gz', compression = 'gzip', lines = True)\n",
        "amazon_reviews_df.head()\n",
        "\n",
        "# reviewerID - ID of the reviewer, e.g. AH2IFH762VY5U\n",
        "# asin - ID of the product, e.g. B00005N7P0\n",
        "# reviewerName - name of the reviewer e.g. ted sedlmayr\t\n",
        "# vote - helpful votes of the review\n",
        "# style - a dictionary of the product metadata, e.g., \"Format\" is \"Hardcover\"\n",
        "# reviewText - text of the review\n",
        "# overall - rating of the product\n",
        "# summary - summary of the review\n",
        "# unixReviewTime - time of the review (unix time)\n",
        "# reviewTime - time of the review (raw)\n",
        "# image - images that users post after they have received the product"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>vote</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>style</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>11 8, 2001</td>\n",
              "      <td>AH2IFH762VY5U</td>\n",
              "      <td>B00005N7P0</td>\n",
              "      <td>ted sedlmayr</td>\n",
              "      <td>for computer enthusiast, MaxPC is a welcome si...</td>\n",
              "      <td>AVID READER SINCE \"boot\"  WAS THE NAME</td>\n",
              "      <td>1005177600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>10 31, 2001</td>\n",
              "      <td>AOSFI0JEYU4XM</td>\n",
              "      <td>B00005N7P0</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>Thank god this is not a Ziff Davis publication...</td>\n",
              "      <td>The straight scoop</td>\n",
              "      <td>1004486400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>False</td>\n",
              "      <td>03 24, 2007</td>\n",
              "      <td>A3JPFWKS83R49V</td>\n",
              "      <td>B00005N7OJ</td>\n",
              "      <td>Bryan Carey</td>\n",
              "      <td>Antiques Magazine is a publication made for an...</td>\n",
              "      <td>Antiques Magazine is Good, but not for Everyone</td>\n",
              "      <td>1174694400</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>False</td>\n",
              "      <td>11 10, 2006</td>\n",
              "      <td>A19FKU6JZQ2ECJ</td>\n",
              "      <td>B00005N7OJ</td>\n",
              "      <td>Patricia L. Porada</td>\n",
              "      <td>This beautiful magazine is in itself a work of...</td>\n",
              "      <td>THE  DISCERNING READER</td>\n",
              "      <td>1163116800</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>07 14, 2014</td>\n",
              "      <td>A25MDGOMZ2GALN</td>\n",
              "      <td>B00005N7P0</td>\n",
              "      <td>Alvey</td>\n",
              "      <td>A great read every issue.</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1405296000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   overall vote  verified  ... unixReviewTime                           style image\n",
              "0        5    9     False  ...     1005177600                             NaN   NaN\n",
              "1        5    9     False  ...     1004486400                             NaN   NaN\n",
              "2        3   14     False  ...     1174694400  {'Format:': ' Print Magazine'}   NaN\n",
              "3        5   13     False  ...     1163116800  {'Format:': ' Print Magazine'}   NaN\n",
              "4        5  NaN      True  ...     1405296000                             NaN   NaN\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZKRqM56Ibb9"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "- How many observations are in amazon_reviews_df? How many features to we have?\n",
        "- What are the label?\n",
        "- What are the proportions of the label categories? - hint: use \n",
        "\n",
        "```\n",
        "len(DataFrame)\n",
        "```\n",
        "\n",
        "print the answers as string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMr2TMUcNOsT"
      },
      "source": [
        "## Solution 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96dml5uhG-1F",
        "outputId": "f4bbcbc9-7286-4454-a16e-53d541f124a7"
      },
      "source": [
        "# How many observations and features\n",
        "metadata = amazon_reviews_df.shape\n",
        "print(metadata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(89689, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2ay94ERIuGv",
        "outputId": "2ce5da22-f8f6-4189-ff43-6898d84fd7c6"
      },
      "source": [
        "print(\"There are \"+str(metadata[0])+\" observations with \"+str(metadata[1])+\" features in the dataset.\")\n",
        "print(f\"There are {str(metadata[0])} observations with {str(metadata[1])} features in the dataset.\")\n",
        "print(\"There are {} observations with {} features in the dataset.\".format(str(metadata[0]),str(metadata[1])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 89689 observations with 12 features in the dataset.\n",
            "There are 89689 observations with 12 features in the dataset.\n",
            "There are 89689 observations with 12 features in the dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HGbB9aAIyPT",
        "outputId": "9a3cce04-2673-43ab-feec-48378b9cfe71"
      },
      "source": [
        "# What are the labels\n",
        "overall = amazon_reviews_df['overall'].unique()\n",
        "print(overall)\n",
        "\n",
        "vote = amazon_reviews_df['vote'].unique()\n",
        "print(vote)\n",
        "\n",
        "print(f\"The label variable is 'overall'.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 3 4 2 1]\n",
            "['9' '14' '13' nan '2' '290' '19' '24' '7' '25' '10' '15' '5' '12' '8' '6'\n",
            " '3' '31' '17' '21' '23' '4' '16' '87' '20' '98' '22' '30' '11' '35' '101'\n",
            " '160' '69' '88' '29' '18' '27' '44' '33' '38' '55' '28' '115' '77' '60'\n",
            " '63' '46' '92' '61' '260' '91' '26' '43' '108' '81' '94' '37' '36' '266'\n",
            " '243' '56' '41' '39' '229' '52' '326' '89' '68' '42' '445' '34' '58' '59'\n",
            " '51' '124' '106' '159' '95' '32' '99' '40' '114' '130' '275' '72' '164'\n",
            " '180' '104' '210' '141' '111' '146' '212' '305' '213' '90' '74' '45'\n",
            " '170' '110' '479' '75' '67' '324' '105' '176' '62' '57' '53' '216' '65'\n",
            " '153' '276' '49' '121' '86' '66' '272' '408' '654' '144' '560' '161'\n",
            " '227' '118' '184' '84' '168' '82' '64' '253' '271' '128' '48' '122' '71'\n",
            " '85' '191' '335' '80' '182' '140' '76' '252' '133' '54' '47' '193' '123'\n",
            " '117' '129' '456' '314' '155' '50' '78' '107' '138' '280' '196' '262'\n",
            " '151' '169' '154' '187' '284' '142' '93' '70' '287' '109' '638' '120'\n",
            " '303' '194' '267' '83' '148' '152' '202' '177' '103' '172' '137' '825'\n",
            " '200' '304' '401' '225' '116' '163' '257' '316' '231' '483' '96' '73'\n",
            " '197' '798' '417' '339' '1,333' '127' '236' '126' '119' '189' '139' '188'\n",
            " '449' '145' '802' '274' '113' '102' '162' '215' '293' '190' '125' '457'\n",
            " '166' '179' '285' '79' '131' '158' '248' '261' '469' '186' '241' '174'\n",
            " '593' '228' '300' '204' '205' '600' '135' '134' '349' '733' '340' '382'\n",
            " '100' '156' '97' '281' '165' '195' '2,467' '440' '1,176' '1,253' '494'\n",
            " '685' '149' '406' '181' '132' '226' '220' '178' '353' '424' '505' '269'\n",
            " '420' '136' '219' '296' '198' '240' '323' '497' '366' '550' '362' '207'\n",
            " '173' '247' '333' '147' '295' '507' '728' '238']\n",
            "The label variable is 'overall'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FzvIuYsJJnH",
        "outputId": "3267e17b-36b0-4c8c-8cfa-f4dc66147e6b"
      },
      "source": [
        "# What are the proportions of the label categories\n",
        "\n",
        "for category in amazon_reviews_df['overall'].unique():\n",
        "  print(f\"Category {category} has a proportion of {str(len(amazon_reviews_df['overall'][amazon_reviews_df['overall']==category])/len(amazon_reviews_df['overall']))}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Category 5 has a proportion of 0.5997390984401655\n",
            "Category 3 has a proportion of 0.07772413562421256\n",
            "Category 4 has a proportion of 0.141332827883018\n",
            "Category 2 has a proportion of 0.05823456611178628\n",
            "Category 1 has a proportion of 0.12296937194081771\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANHVN5lOLDUm"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "- How can we ensure that we have equal proportions of the label category in our data?\n",
        "- How can we convert the label into a positive / negative sentiment score?\n",
        "*italicized text*\n",
        "\n",
        "print the answers as string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu7LVToxNNHa"
      },
      "source": [
        "## Solution 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWsa3MaCLLTF"
      },
      "source": [
        "# We want to create as many 1s as 0s.\n",
        "# We choose category == 5 as 1 and category == 1 as 0\n",
        "# Category == 1 occurs less often than category == 5.\n",
        "# We will choose a random sample from category ==5 in the same amount of reviews as category ==1.\n",
        "\n",
        "sentiment_list = []\n",
        "data_df = amazon_reviews_df[['overall','reviewText']][amazon_reviews_df['overall'].isin([1,5])].dropna()\n",
        "\n",
        "for index, row in data_df.iterrows():\n",
        "  if row['overall'] ==1:\n",
        "    sentiment_list.append(0)\n",
        "  elif row['overall'] ==5:\n",
        "    sentiment_list.append(1)\n",
        "\n",
        "data_df['sentiment'] = sentiment_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "AwY_gblCMHg1",
        "outputId": "bfeae7a8-557f-4f30-8fc8-7cc847d3b272"
      },
      "source": [
        "data_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>for computer enthusiast, MaxPC is a welcome si...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>Thank god this is not a Ziff Davis publication...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>This beautiful magazine is in itself a work of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>A great read every issue.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>I've read Maximum PC (MPC) for many years. The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89684</th>\n",
              "      <td>5</td>\n",
              "      <td>This was a nice surprise for my boyfriend. He ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89685</th>\n",
              "      <td>1</td>\n",
              "      <td>Magazine looks like it is printed on recycled ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89686</th>\n",
              "      <td>5</td>\n",
              "      <td>cant go wrong with an SI subscription\\nvery pl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89687</th>\n",
              "      <td>5</td>\n",
              "      <td>This magazine is by far my all time favorite o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89688</th>\n",
              "      <td>5</td>\n",
              "      <td>Nice magazine. Good info and articles.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64796 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       overall                                         reviewText  sentiment\n",
              "0            5  for computer enthusiast, MaxPC is a welcome si...          1\n",
              "1            5  Thank god this is not a Ziff Davis publication...          1\n",
              "3            5  This beautiful magazine is in itself a work of...          1\n",
              "4            5                          A great read every issue.          1\n",
              "6            5  I've read Maximum PC (MPC) for many years. The...          1\n",
              "...        ...                                                ...        ...\n",
              "89684        5  This was a nice surprise for my boyfriend. He ...          1\n",
              "89685        1  Magazine looks like it is printed on recycled ...          0\n",
              "89686        5  cant go wrong with an SI subscription\\nvery pl...          1\n",
              "89687        5  This magazine is by far my all time favorite o...          1\n",
              "89688        5             Nice magazine. Good info and articles.          1\n",
              "\n",
              "[64796 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "FlGj3mUlL2mT",
        "outputId": "d4585ea8-ff6e-4598-a6ed-c37a6fe7c229"
      },
      "source": [
        "data_df = pd.DataFrame()\n",
        "data_df= amazon_reviews_df[amazon_reviews_df['overall']==1]\n",
        "count_reviews=len(amazon_reviews_df[amazon_reviews_df['overall']==1])\n",
        "random_sample_df = amazon_reviews_df[amazon_reviews_df['overall']==5].sample(n=count_reviews,replace=False, random_state=42)\n",
        "data_df=data_df.append(random_sample_df)\n",
        "data_df['overall'].hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3347d9d750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOXEOn7FMZHK",
        "outputId": "ac4a59db-6afe-403c-b6f3-fa577ad669db"
      },
      "source": [
        "# Convert the label into a positive / negative sentiment score\n",
        "\n",
        "sentiment_list = []\n",
        "for index, row in data_df.iterrows():\n",
        "  if row['overall']==1:\n",
        "    sentiment_list.append(0)\n",
        "  elif row['overall']==5:\n",
        "    sentiment_list.append(1)\n",
        "  \n",
        "data_df['sentiment']=sentiment_list\n",
        "\n",
        "# A simple check to see if the sentiment score is balanced is to take the mean of the variable that should be 0.5\n",
        "\n",
        "print(f\"if the proportion is correct we will see 'True' here : {data_df['sentiment'].mean()==0.5}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "if the proportion is correct we will see 'True' here : True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "Qiplj_cnMpr7",
        "outputId": "5887d3f4-d4a7-442c-aca5-fff0ec49caab"
      },
      "source": [
        "data_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>vote</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>style</th>\n",
              "      <th>image</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>02 6, 2012</td>\n",
              "      <td>A90UMUUG7DFCU</td>\n",
              "      <td>B00005N7P0</td>\n",
              "      <td>E. E</td>\n",
              "      <td>First issue I got was June 2010 and last issue...</td>\n",
              "      <td>you will never  get 12 issues</td>\n",
              "      <td>1328486400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>True</td>\n",
              "      <td>01 31, 2004</td>\n",
              "      <td>A1IWT6KM1X8PNS</td>\n",
              "      <td>B00005N7PS</td>\n",
              "      <td>AZS</td>\n",
              "      <td>Unbelievable amount of ads.\\nFor $5 a year it ...</td>\n",
              "      <td>At least 90% ads</td>\n",
              "      <td>1075507200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>False</td>\n",
              "      <td>09 3, 2003</td>\n",
              "      <td>A22X4XUPKF66MR</td>\n",
              "      <td>B00005N7PS</td>\n",
              "      <td>D. H. Richards</td>\n",
              "      <td>When I was in high school Details was a pretty...</td>\n",
              "      <td>next to no content, but plenty of ads...</td>\n",
              "      <td>1062547200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>False</td>\n",
              "      <td>07 15, 2003</td>\n",
              "      <td>A1RPTVW5VEOSI</td>\n",
              "      <td>B00005N7PS</td>\n",
              "      <td>Michael J. Edelman</td>\n",
              "      <td>If you're the kind of man who looks at himself...</td>\n",
              "      <td>THE Magazine for the Self-Centered Male</td>\n",
              "      <td>1058227200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>False</td>\n",
              "      <td>01 16, 2003</td>\n",
              "      <td>AWGAHK04B1SO4</td>\n",
              "      <td>B00005N7PS</td>\n",
              "      <td>butterfly</td>\n",
              "      <td>i bought this magazine subscription for my hus...</td>\n",
              "      <td>Ridiculously Boring Magazine</td>\n",
              "      <td>1042675200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38162</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>02 1, 2016</td>\n",
              "      <td>A1GE78P2NKDI3</td>\n",
              "      <td>B00007BK3L</td>\n",
              "      <td>G. M. FIRESTONE</td>\n",
              "      <td>Great way to keep up with world news and other...</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1454284800</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73036</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>02 8, 2016</td>\n",
              "      <td>A2GUGLO85TGNNU</td>\n",
              "      <td>B00YQH98G0</td>\n",
              "      <td>Megan Edmonds</td>\n",
              "      <td>I ordered this for my boyfriend and he loves i...</td>\n",
              "      <td>Excellent articles and journalists</td>\n",
              "      <td>1454889600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32803</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>07 28, 2017</td>\n",
              "      <td>A1ROPZX2MQ5V1D</td>\n",
              "      <td>B00006LKH1</td>\n",
              "      <td>Laurie  Smith</td>\n",
              "      <td>Love getting this magazine at home</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1501200000</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37194</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>02 27, 2016</td>\n",
              "      <td>A3ECKUOE47QUN8</td>\n",
              "      <td>B00007B10Y</td>\n",
              "      <td>Ana</td>\n",
              "      <td>I love this magazine. My 12 years old also lik...</td>\n",
              "      <td>Nice reading</td>\n",
              "      <td>1456531200</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9330</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>07 5, 2014</td>\n",
              "      <td>A3HJ62ZXAI1SVH</td>\n",
              "      <td>B00005N7Q5</td>\n",
              "      <td>Evan</td>\n",
              "      <td>I've always enjoyed this magazine since I was ...</td>\n",
              "      <td>informative and enjoyable</td>\n",
              "      <td>1404518400</td>\n",
              "      <td>{'Format:': ' Kindle Edition'}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22058 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       overall vote  verified  ...                           style image sentiment\n",
              "46           1  NaN     False  ...                             NaN   NaN         0\n",
              "71           1   10      True  ...                             NaN   NaN         0\n",
              "72           1   31     False  ...                             NaN   NaN         0\n",
              "73           1   17     False  ...                             NaN   NaN         0\n",
              "74           1   21     False  ...                             NaN   NaN         0\n",
              "...        ...  ...       ...  ...                             ...   ...       ...\n",
              "38162        5  NaN      True  ...  {'Format:': ' Print Magazine'}   NaN         1\n",
              "73036        5  NaN      True  ...                             NaN   NaN         1\n",
              "32803        5  NaN      True  ...  {'Format:': ' Print Magazine'}   NaN         1\n",
              "37194        5  NaN      True  ...  {'Format:': ' Print Magazine'}   NaN         1\n",
              "9330         5  NaN      True  ...  {'Format:': ' Kindle Edition'}   NaN         1\n",
              "\n",
              "[22058 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCCtWimrM9gS"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "- Which index has the longest, which one is the shortest review comment in length? - Use a list comprehension. \n",
        "- Are there more than one with the same count?\n",
        "- Take the longest. How many word tokens does it contain? How many sentences? \\\\\n",
        "Hint: the index is 64738; use the nltk tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByFCJXaBNJ4i"
      },
      "source": [
        "## Solution 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC9thCVoMrGo",
        "outputId": "48e23543-518b-4376-b1b4-96c6029f52b6"
      },
      "source": [
        "# Which index has the longes, which one is the shortest review in count of symbols\n",
        "# Longest / Shortest\n",
        "data_df['length']=[len(str(review)) for review in data_df['reviewText']]\n",
        "longest_index = data_df.index[data_df['length']==data_df['length'].max()].values[0]\n",
        "shortest_index = data_df.index[data_df['length']==data_df['length'].min()].values[0]\n",
        "print(f\"The longest review is a index {longest_index}, the shortest has index {shortest_index}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The longest review is a index 64738, the shortest has index 11286.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQUrihImNYwp",
        "outputId": "86c7961f-8928-4e64-ad25-bd3379f69cb1"
      },
      "source": [
        "# Are there more than one with same count\n",
        "\n",
        "count_longest = len(data_df[data_df['length']==data_df['length'].max()])\n",
        "count_shortest = len(data_df[data_df['length']==data_df['length'].min()])\n",
        "\n",
        "print(f\"the longest count occurs in {count_longest} reviews, the shortest in {count_shortest} reviews.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the longest count occurs in 1 reviews, the shortest in 10 reviews.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4NRiSORQKd7",
        "outputId": "75056e41-f3cf-4cd4-e18a-4b9337cca685"
      },
      "source": [
        "# How many word tokens does it contain? How many sentences?\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt')\n",
        "text = data_df['reviewText'][data_df.index==longest_index].values[0]\n",
        "\n",
        "text_wordprocessed = word_tokenize(text)\n",
        "text_sentprocessed = sent_tokenize(text)\n",
        "\n",
        "words_count = len(text_wordprocessed)\n",
        "sentence_count = len(text_sentprocessed)\n",
        "print(f\"The longest review contains {words_count} words and {sentence_count} sentences.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "The longest review contains 3297 words and 98 sentences.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMAG4eyWQm7c"
      },
      "source": [
        "## Question 4\n",
        "\n",
        "- What word occurs most often in the longest review? \\\\\n",
        "Hint: use the CountVectorizer\n",
        "\n",
        "```\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "```\n",
        "you can transpose dataframes by\n",
        "\n",
        "\n",
        "```\n",
        "data_df.T\n",
        "```\n",
        "and you can select a column then by index, which is an integer.\n",
        "\n",
        "- Filter for stopwords. Does it make sense to do this in the present example? \\\\\n",
        "Hint: Use nltk stopwords \\\\\n",
        "\n",
        "\n",
        "```\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "```\n",
        "The Vectorizer needs a string in a list to work. You can reassemble lists to strings by \n",
        "\n",
        "```\n",
        "processed_string= \" \".join(processed_list)```\n",
        "```\n",
        "- What is the TF-IDF frequency for the most frequent word? Is it a different word than before?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uwcsgssQvzM"
      },
      "source": [
        "## Solution 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mzzqI5HQk88",
        "outputId": "5a6a405b-0256-4092-ef0d-e47ff67cf70f"
      },
      "source": [
        "# What word occurs most often in the longest review?\n",
        "\n",
        "#Count occurrences of individual terms over docs in corpus\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "\n",
        "#Make sure to transform string to list\n",
        "\n",
        "longest_list = [data_df['reviewText'][data_df.index==longest_index].values[0]]\n",
        "\n",
        "countvectorizer = CountVectorizer(analyzer= 'word')\n",
        "count_wm = countvectorizer.fit_transform(longest_list)\n",
        "\n",
        "count_tokens = countvectorizer.get_feature_names()\n",
        "\n",
        "countvect_df = pd.DataFrame(data = count_wm.toarray(), columns = count_tokens)\n",
        "\n",
        "word = countvect_df.T.sort_values(0,ascending=False)[0].head(1).index[0]\n",
        "\n",
        "count = countvect_df.T.sort_values(0,ascending=False)[0].head(1)[0]\n",
        "\n",
        "print(f\"the word '{word}' occurs {count} times in the review.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the word 'the' occurs 147 times in the review.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMi4BAozQj58",
        "outputId": "dad63ee9-218b-4e93-e9a1-d2ba04372524"
      },
      "source": [
        "# Filter for stopwords. Does it make sense to do this in the present example\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "processed_list = []\n",
        "\n",
        "for word in longest_list[0].split(\" \"):\n",
        "  if word not in STOPWORDS:\n",
        "    processed_list.append(word)\n",
        "processed_sentence = \" \".join(processed_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI9qsYJqQWnC",
        "outputId": "d0d6e58a-2395-4552-dbc2-9f19e596cbc2"
      },
      "source": [
        "# The vectorizer expects a list of individual docs.\n",
        "# We have only one doc, our longest review.\n",
        "\n",
        "representation_as_list = list()\n",
        "\n",
        "representation_as_list.append(processed_sentence)\n",
        "\n",
        "count_wm = countvectorizer.fit_transform(representation_as_list)\n",
        "count_tokens = countvectorizer.get_feature_names()\n",
        "\n",
        "countvect_df = pd.DataFrame(data = count_wm.toarray(),columns = count_tokens)\n",
        "\n",
        "word = countvect_df.T.sort_values(0,ascending=False)[0].head(1).index[0]\n",
        "count = countvect_df.T.sort_values(0,ascending=False)[0].head(1)[0]\n",
        "\n",
        "print(f\"the word '{word}' occurs {count} times in the review.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the word 'ski' occurs 42 times in the review.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCsTWup9UAmI",
        "outputId": "9e4c3670-a0e8-4790-ba38-a1d023f3b962"
      },
      "source": [
        "# What is the Tf-idf frequency for the most frequent word\n",
        "# Is it different than the one found out from CountVectorizer\n",
        "\n",
        "tfidfvectorizer = TfidfVectorizer(analyzer='word')\n",
        "\n",
        "tfidf_model = tfidfvectorizer.fit_transform(representation_as_list)\n",
        "\n",
        "tfidf_tokens = tfidfvectorizer.get_feature_names()\n",
        "tfidf_df = pd.DataFrame(data = tfidf_model.toarray(),columns = tfidf_tokens)\n",
        "wordfreq_df = tfidf_df.T.sort_values(0, ascending=False).rename(columns={0:'frequency'})\n",
        "print(f\"The word '{wordfreq_df.head(1).index[0]}' has a TF-IDF frequency of {wordfreq_df['frequency'].head(1)[0]}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The word 'ski' has a TF-IDF frequency of 0.43294367938410694.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms4ZSGJNUWN1"
      },
      "source": [
        "## Question 5\n",
        "- Parse two dataframes that contain:\n",
        "1. Words from all reviews with either sentiment =0 or =1 \\\\\n",
        "2. Adjectives\n",
        "3. Not stopwords \n",
        "4. Lemmas\n",
        "5. TF-IDF Frequencies \n",
        "\n",
        "Hint: use spacy; for a glossary you can treat ALL reviews as ONE corpus\n",
        "```\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "```\n",
        "\n",
        "You check for Adjectives and stopwords in one logic check:\n",
        "\n",
        "```\n",
        "token.pos_ == 'ADJ' and token.is_stop is not True\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zvdSLr2UjR0"
      },
      "source": [
        "## Solution 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slUhCuPOURO2"
      },
      "source": [
        "import spacy \n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bigv4aW1UtKX",
        "outputId": "f46ee16c-5ae3-426b-b11d-7872dedf2e5d"
      },
      "source": [
        "%%time\n",
        "# We are building a corpus across all reviews, so our doc IS actually all reviews. \n",
        "negative_df = data_df[data_df['sentiment']==0]\n",
        "\n",
        "# We iterate through all reviews, spacy-parse them and extract adverbs.\n",
        "\n",
        "negative_adjective_list = []\n",
        "for index, row in negative_df.iterrows():\n",
        "  doc = nlp(str(row['reviewText']))\n",
        "  \n",
        "  for token in doc:\n",
        "    if token.pos_ == 'ADJ' and token.is_stop is not True:\n",
        "      negative_adjective_list.append(token.lemma_)\n",
        "\n",
        "negative_string = \" \".join(negative_adjective_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11min, sys: 8.64 s, total: 11min 8s\n",
            "Wall time: 11min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWk-ssT-U5C8",
        "outputId": "f54fdd0a-fcca-4692-c0e8-7a159739c8d7"
      },
      "source": [
        "%%time\n",
        "# We are building a corpus across all reviews, so our doc IS actually all reviews. \n",
        "positive_df = data_df[data_df['sentiment']==1]\n",
        "\n",
        "# We iterate through all reviews, spacy-parse them and extract Adjective. \n",
        "\n",
        "positive_adjective_list = []\n",
        "for index, row in positive_df.iterrows():\n",
        "  doc = nlp(str(row['reviewText']))\n",
        "  \n",
        "  for token in doc:\n",
        "    if token.pos_ == 'ADJ' and token.is_stop is not True:\n",
        "      positive_adjective_list.append(token.lemma_)\n",
        "\n",
        "positive_string = \" \".join(positive_adjective_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10min 13s, sys: 8.34 s, total: 10min 22s\n",
            "Wall time: 10min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQvmIO9bVOz-"
      },
      "source": [
        "# Now process the data with the tf-idf vectorizer\n",
        "\n",
        "positive_list = []\n",
        "positive_list.append(positive_string)\n",
        "\n",
        "tfidfvectorizer = TfidfVectorizer(analyzer='word')\n",
        "tfidf_model = tfidfvectorizer.fit_transform(positive_list)\n",
        "tfidf_tokens = tfidfvectorizer.get_feature_names()\n",
        "tfidf_df = pd.DataFrame(data = tfidf_model.toarray(),columns = tfidf_tokens)\n",
        "pos_df = tfidf_df.T.sort_values(0, ascending=False).rename(columns={0:'frequency'})\n",
        "\n",
        "negative_list = []\n",
        "negative_list.append(negative_string)\n",
        "\n",
        "tfidfvectorizer = TfidfVectorizer(analyzer='word')\n",
        "tfidf_model = tfidfvectorizer.fit_transform(negative_list)\n",
        "tfidf_tokens = tfidfvectorizer.get_feature_names()\n",
        "tfidf_df = pd.DataFrame(data = tfidf_model.toarray(),columns = tfidf_tokens)\n",
        "neg_df = tfidf_df.T.sort_values(0, ascending=False).rename(columns={0:'frequency'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFPIgei3Vepm"
      },
      "source": [
        "## Question 6 (NOT RELEVANT FOR EXAM)\n",
        "\n",
        "- Create a simple classifier and predict the sentiment for the Review with Index 64738"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah06PnkSVnCK"
      },
      "source": [
        "## Solution 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tujZ-01qVb0d"
      },
      "source": [
        "def sentiment_analyzer(text):\n",
        "  score_list = list()\n",
        "  doc = nlp(text)\n",
        "  for token in doc:\n",
        "    if token.pos_ == 'ADJ' and token.is_stop is not True:\n",
        "      try:\n",
        "        pos_score = pos_df['frequency'][pos_df.index==token.lemma_].values[0]\n",
        "      except IndexError:\n",
        "        pos_score = 0\n",
        "      try:\n",
        "        neg_score = neg_df['frequency'][neg_df.index==token.lemma_].values[0]\n",
        "      except IndexError:\n",
        "        neg_score = 0\n",
        "      if pos_score == neg_score:\n",
        "        score_list.append(0)\n",
        "      elif pos_score > neg_score:\n",
        "        score_list.append(1)\n",
        "      elif pos_score < neg_score:\n",
        "        score_list.append(-1)\n",
        "\n",
        "  return sum(score_list)/len(score_list)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvRSWJo2WQpN",
        "outputId": "05372cf7-4e90-4e88-ce84-06493eef0f73"
      },
      "source": [
        "index = 64738\n",
        "\n",
        "predicted_sentiment = sentiment_analyzer(data_df['reviewText'][index])\n",
        "actual_sentiment = data_df['sentiment'][index]\n",
        "\n",
        "if predicted_sentiment > 0 and actual_sentiment == 1:\n",
        "  result = \"True Positive\"\n",
        "elif predicted_sentiment < 0 and actual_sentiment == 0:\n",
        "  result = \"True Negative\"\n",
        "elif predicted_sentiment > 0 and actual_sentiment == 0:\n",
        "  result = \"False Positive\"\n",
        "elif predicted_sentiment < 0 and actual_sentiment == 1:\n",
        "  result = 'False Negative'\n",
        "\n",
        "print(f\"Index {index} is a {result}: it has predicted sentiment {predicted_sentiment} and actual sentiment {actual_sentiment} \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index 64738 is a True Negative: it has predicted sentiment -0.6395939086294417 and actual sentiment 0 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}